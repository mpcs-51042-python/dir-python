{
  "hash": "c7e3bbb26610ebe931d410e1bef527c5",
  "result": {
    "engine": "jupyter",
    "markdown": "# Data Structures {#sec-data-structures}\n\n---\n\n**Goals**\n\n- Explore the differences between **lists & arrays** for sequential data structures.\n- Examine how implementation choices can affect performance using **stacks & queues**.\n- Learn how to implement **hash tables**, the data structure that powers Python's `dict`.\n\n---\n\n## What are data structures?\n\nData structures are ways of organizing data in working memory.\nThey are not purely *inventions* of computer science, but reflect real-world patterns of organizing information.\n\nData structures like **stacks**, **queues**, and **trees** mimic the way we already think about the world.\n\nA stack of documents on a desk has the same properties as the stack data structure: the first document finds its way to the bottom of the stack as new ones come in & the document on the top of the stack gets your attention.\nThe queue data structure even more clearly behaves its real-world counterpart: standing in a line being processed by order of arrival is a regular occurrence.\nAnd trees map to all kinds of hierarchical relationships: genealogy, organizational structure, file systems, HTML.\n\nData structures help us model real-world scenarios and play an essential role in writing performant programs.\nAs we'll see, the choice of data structure can often make a big difference in the complexity class of an algorithm.\n\n## Arrays\n\nWe'll start by looking at one of the most fundamental data structures: **arrays**.\n\nArrays are collections of items that are stored in *contiguous memory*.\n\nThe RAM in your computer can be thought of as a sequential set of boxes that can store individual values.\nThe operating system and programming language assign these blocks to your program as it requires memory for variables.\n\nIf you were running a Python program with variables:\n\n```python\ns = \"Hello\"\nx = 100*100\ny = 36912\n```\n\n\nA snapshot of that memory might look like:\n\n| Address | Owned by | Contents |\n|-|-|-|\n| 0x7000-0x8000 | Safari | ... |\n| 0x8016 | **your program** | H  |\n| 0x8020 | **your program** | e |\n| 0x8024 | **your program** | l |\n| 0x8028 | **your program** | l |\n| 0x8032 | **your program** | o |\n| 0x8090-0x8400 | Spotify | ... |\n| 0x8500 | **your program** | 10000 |\n| 0x8504 | **your program** | 36912 |\n| 0x8600-0x9000 | Safari | ... |\n\nThis is a simplified version showing a small range of memory. The important details:\n\n- Each location in memory has a sequential **address** associated with it.\n- The memory is allocated in blocks of a standard size (here I am using 4 byte blocks).\n- Programs are not guaranteed **contiguous** memory, both your program and Safari have disjoint chunks of memory.\n- It is often faster to access contiguous memory than to seek around at random within this space.\n\nAn **array** is a data structure that consists of a block of contiguous memory to store many similar items near one another.\n\nIn a language where we can request specifically sized blocks of memory (such as **C**) you might have:\n\n```c\n// this is C code, not Python\nint my_array[5] = {1, 2, 3, 4, 5};\n```\n\nThis would allocate memory owned by your program in a contiguous block of 5 integers:\n\n| Address | Contents |\n|-|-|-|\n| 0x10000 | 1 |\n| 0x10004 | 2 | \n| 0x10008 | 3 |\n| 0x10012 | 4 | \n| 0x10016 | 5 |\n\nThe variable `array` would track the starting address, here `0x10000`.\n\nCode that reads or sets a particular value such as `my_array[3] = 100` then needs to compute the *offset*.\n\nSince we have **contiguous memory** and a **fixed block size** (of 4 bytes for an integer) the language can perform these operations in constant $O(1)$ time.\n\n`memory_location = initial_offset + block_size * index`\n\nSo to find `my_array[3]` that would be:\n\n`memory_location = 0x10000 + 4 * 3 = 0x10012`\n\n*This is why arrays are zero-indexed!* The first box with `index=0` becomes `initial_offset + block_size * 0`, or just `initial_offset`.\n\nEach array will have its own `initial_offset` and `block_size`, the latter determined by the type of data being stored.\n\n### Python's `list`\n\nIn Python, `list` is implemented as an array. \n\nIt has two properties that not all arrays share however: \n\n1. It can store items of *heterogeneous* type.\n1. It can expand as needed, we do not need to pre-define how many elements are in the list.\n\nArrays must have fixed block sizes for the arithmetic above to work, this seems like it may pose problems for both of these use cases.\n\nTo allow heterogeneous data (including data that may change size),\nthe object stored in each cell of the array is a C type (called `PyObject`) that we do not interact with directly from Python.\n\nInstead of each box storing the actual value, they store the `PyObject`, which in turn stores a pointer or reference to the actual data, which will be stored elsewhere:\n\n![](python-list.png)\n\nNow instead of a direct lookup, the index-based lookup returns the address of the actual data.\nThis remains $O(1)$ since this extra step is a constant operation, and will not take more time as the number of items grows.\n\nAllowing an array to grow takes another trick: we are going to over-allocate memory.\n\nWhen you create a new list Python allocates a block of memory that is large enough to hold the list, and then some extra space.\n\n```python\nx = [1, 2, 3]\n```\n\nThe language might allocate eight memory blocks instead of three.\n\nNote 1: Numbers for illustration only, implementation details will vary.\n\nNote 2: I am not showing the extra level of indirection here, instead using the notation `-> 1` to remind you that the data stored in that\nblock is not the actual value, but a reference to it.\n\n| Address | Contents |\n|-|-|\n| 0x5000 | --> 1 |\n| 0x5004 | --> 2 |\n| 0x5008 | --> 3 |\n| 0x5012 | |\n| 0x5016 | |\n| 0x5020 | |\n| 0x5024 | |\n| 0x5028 | |\n\nNow when you call `x.append(4)`, Python has room for it already.\n\nThis keeps the operation $O(1)$, but at the cost of keeping around some empty blocks of memory.\n\nBut this would only allow our lists to grow up to this arbitrary capacity.\nWhat happens in practice is that Python will grow the **capacity** when some threshold is exceeded.\n\nIn our hypothetical list, we are now using four of the allocated eight blocks.\n\n```python\nx.append(5)\nx.append(6)\nx.append(7)\nx.append(8)\nx.append(9) # what happens?!\n```\n\nAs we know, this code will run fine!\nPython tracks how many cells are used, and if an insertion would cause the capacity to be exceeded it **moves the entire list**.\n\nIt cannot just expand in place, since the adjacent memory is likely used by other variables or even other programs.\nThis means that the occasional insertion does need to do more work, copying the list over to a new block of **contiguous memory**.\n\nSo after the additional insertions our list may have had it's items moved, and new additional capacity allocated:\n\n\n| Address | Contents |\n|-|-|\n| 0x9100 | --> 1 |\n| 0x9104 | --> 2 |\n| 0x9108 | --> 3 |\n| 0x9112 | --> 4|\n| 0x9116 | --> 5|\n| 0x9120 | --> 6|\n| 0x9124 | --> 7|\n| 0x9128 | --> 8|\n| 0x9128 | --> 9|\n| 0x9128 | |\n| 0x9128 | |\n| 0x9128 | |\n\nNotice it again over allocates.\nBecause this move can be expensive, it will add additional padding so that the next move does not come right away.\n\nBecause lists (arrays) are typically accessed much more often than they grow, this is a good trade-off in most cases.\n\nIn practice, the amount of padding that Python adds would affect the **memory usage vs. performance** of this data structure.\n\n## Linked Lists\n\nIn Python we typically use a `list` or `tuple` to store an *ordered sequence* of items.\nThis is contrasted with an unordered collection, such as a `set`.\n\nThere is another data structure that is useful for *ordered sequences*:\n\n**Linked lists** are ordered collections of items, but use non-contiguous memory.\n\nEach item in the list contains a pointer to the next item in the list.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# data-structures/linked_list.py\nclass Node:\n    def __init__(self, value, next=None): \n        self.value = value\n        self.next = next\n\nclass LinkedList:\n    def __init__(self):\n        self.root = None\n\n    def __len__(self):\n        count = 0\n        cur = self.root\n        while cur is not None:\n            count += 1\n            cur = cur.next\n\n    def append(self, value):\n        # new tail node\n        new = Node(value)\n        # special case for first node\n        if self.root is None:\n            self.root = new\n        else:\n            cur = self.root\n            # iterate to end-1\n            while cur.next is not None:\n                cur = cur.next\n            # append node\n            cur.next = new\n            \n    def prepend(self, value):\n        # add new node that points at old root\n        new = Node(value, self.root)\n        self.root = new\n\n    def __str__(self):\n        s = \"\"\n        cur = self.root\n        while cur:\n            s += f\"{cur.value} -> \"\n            cur = cur.next\n        s += \"END\"\n        return s\n\nll = LinkedList()\nll.append(1)\nll.append(2)\nll.prepend(0)\nll.prepend(-1)\nll.append(3)\nprint(ll)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-1 -> 0 -> 1 -> 2 -> 3 -> END\n```\n:::\n:::\n\n\nTo use an implementation of a **doubly-linked list**, we use `collections.deque`.\n\nThis stores forward & backward references allowing bidirectional traversal at a slightly higher cost.\n\n### Linked List vs. Array\n\n| Operation | Linked List | Array |\n|-----------|-------------|--------|\n| Access by Index | O(n) | O(1) | Arrays use direct memory addressing |\n| Insert/Delete at Start | O(1) | O(n) | Arrays need to shift all elements |\n| Insert/Delete at End | O(1) | O(1)* | *Amortized for dynamic arrays |\n| Insert/Delete at Middle | O(n) | O(n) | List will traverse, arrays will shift items. |\n\nIt is also common to have a doubly-linked list, where each item contains a pointer to the next item and the previous item.\n\n## Stacks\n\nOne of the most common data structures is the stack.\n\nA stack is a data structure that enables Last In, First Out processing.\n\nLIFO means that the last item added to the stack is the first item removed.\n\nThe common analogy is a stack of plates.\n\nYou also deal with a stack whenever calling functions: the last function called is the first to return.\n\nInsertions & deletions happen on the same end of the data structure.\n\n### Call Stack Example\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef a():\n    print(\"a on call stack\")\n    b()\n    print(\"a off call stack\")\n\ndef b():\n    print(\"  b on call stack\")\n    c()\n    print(\"  b off call stack\")\n\ndef c():\n    print(\"    c on call stack\")\n    print(\"    c off call stack\")\n\na()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\na on call stack\n  b on call stack\n    c on call stack\n    c off call stack\n  b off call stack\na off call stack\n```\n:::\n:::\n\n\n**What data structure is best for a stack?**\n\n\n### Example Implementation\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nclass Stack:\n    def __init__(self):\n        # because it is faster to add/remove at the end of a list\n        # we'll treat the end of the list as the top of the stack\n        self.items = []\n\n    def push(self, item):\n        self.items.append(item)\n\n    def pop(self):\n        return self.items.pop()\n\n    def __str__(self):\n        \"\"\"Return a string representation of the stack.\"\"\"\n        output = []\n        output.append(f\"[ {self.items[-1]} ] <- top\")\n        for item in reversed(self.items[:-1]):\n            output.append(f\"[ {item} ]\")\n        return \"\\n\".join(output)\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nstack = Stack()\nstack.push(1)\nstack.push(2)\nstack.push(3)\nprint(stack)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[ 3 ] <- top\n[ 2 ]\n[ 1 ]\n```\n:::\n:::\n\n\nHow would a linked list perform?\n\n## Queues\n\nIn a queue, the first item added is the first item removed. First In, First Out, or FIFO.\n\nThe common analogy is a line at a grocery store.\n\nInsertions & deletions happen on opposite ends of the data structure.\n\nWhat data structure is best for a queue?\n\n### Example Implementation\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nclass ArrayQueue:\n    def __init__(self, _iterable=None):\n        if _iterable:\n            self._data = list(_iterable)\n        else:\n            self._data = []\n\n    def push(self, item):\n        # adding to the end of the list is faster than the front\n        self._data.append(item)\n\n    def pop(self):\n        # only change from `Stack` is we remove from the other end\n        # this can be slower, why?\n        return self._data.pop(0)\n\n    def __len__(self):\n        return len(self._data)\n\n    def __repr__(self):\n        return \" TOP -> \" + \"\\n        \".join(\n            f\"[ {item} ]\" for item in reversed(self._data)\n        )\n\n```\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom collections import deque\n\n\nclass DequeQueue:\n    def __init__(self, _iterable=None):\n        if _iterable:\n            self._data = deque(_iterable)\n        else:\n            self._data = deque()\n\n    def push(self, item):\n        self._data.append(item)\n\n    def pop(self):\n        return self._data.popleft()\n\n    def __len__(self):\n        return len(self._data)\n\n    def __repr__(self):\n        return \" TOP -> \" + \"\\n        \".join(\n            f\"[ {item} ]\" for item in reversed(self._data)\n        )\n```\n:::\n\n\n### Testing Queue Performance\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nimport timeit\n\nnumber = 1_000_000\n\nelapsed = timeit.timeit(\n    \"queue.push(1)\",\n    setup=\"queue = QueueCls()\",\n    globals={\"QueueCls\": ArrayQueue},\n    number=number,\n)\nelapsed2 = timeit.timeit(\n    \"queue.push(1)\",\n    setup=\"queue = QueueCls()\",\n    globals={\"QueueCls\": DequeQueue},\n    number=number,\n)\nprint(f\"{number}x ArrayQueue.push, took\", elapsed)\nprint(f\"{number}x DequeQueue.push, took\", elapsed2)\nprint(f\"DequeQueue is {(elapsed-elapsed2) / elapsed * 100:.3f}% faster\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1000000x ArrayQueue.push, took 0.018829124979674816\n1000000x DequeQueue.push, took 0.02102616708725691\nDequeQueue is -11.668% faster\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nnumber = 10_000\n\nelapsed = timeit.timeit(\n    \"queue.pop()\",\n    setup=\"queue = QueueCls([0] * 1000000)\",\n    globals={\"QueueCls\": ArrayQueue},\n    number=number,\n)\nelapsed2 = timeit.timeit(\n    \"queue.pop()\",\n    setup=\"queue = QueueCls([0] * 1000000)\",\n    globals={\"QueueCls\": DequeQueue},\n    number=number,\n)\nprint(f\"{number}x ArrayQueue.pop, took\", elapsed)\nprint(f\"{number}x DequeQueue.pop, took\", elapsed2)\nprint(f\"DequeQueue is {(elapsed-elapsed2) / elapsed * 100:.3f}% faster\")\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10000x ArrayQueue.pop, took 1.1330664589768276\n10000x DequeQueue.pop, took 0.00021216599270701408\nDequeQueue is 99.981% faster\n```\n:::\n:::\n\n\n### Queue Performance\n\n| Operation | ArrayQueue | DequeQueue |\n| --------- | ---------- | ---------- |\n| push      | O(1)       | O(1)       |\n| pop       | O(n)       | O(1)       |\n\n## Hash Tables\n\nA hash table is a data structure that maps a unique identifying key with some associated value.\n\nA `dict` is an implementation of a hash table.\n\nIf all we wanted to do was associate items with keys, we could store a list of `(key, value)` tuples in a list.\n\nThen to look up an item, we would search the list by iterating through and looking for the `key`.\nThis would be $O(N)$ (or $O(\\log N)$ if we can keep the table sorted).\n\nLooking up items in a hash table or dictionary is an important task, almost everything in Python relies on the performance of dictionaries.\n\nAs we'll see, we can instead write algorithms that will make modifying & accessing individual hash table cells $O(1)$.\n\n### Hashing\n\nA key piece of writing a hash table is to use a **hashing function**.\n\nThis is a function that will convert a value (often a string) to an arbitrary but consistent integer.\n\nTo see how this will help, let's first model a simple hash table with fixed capacity of 10 using a list of 10 empty elements:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ncapacity = 10\nstorage = [None] * capacity\n```\n:::\n\n\nFor simplicity we'll stick to string keys.\n\nWhen we get a key-value pair, we need to assign it a bucket.\n\nHow can we write a function that takes a string and assigns it to a bucket?\n\n1. Turn the string into a number. This is our **hash function**\n2. Take (number % capacity) and assign the item to that cell in our array.\n\nFor example:\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ndef strhash(key):\n    # ord converts a character to it's numeric representation\n    #   ord(\"A\") == 65\n    #   ord(\"z\") == 122\n    # etc.\n    return sum(ord(letter) for letter in key)\n```\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfor word in (\"bear\", \"fox\"):\n    print(f\"strhash({word}) =\", strhash(word), \"    % 10 = \", strhash(word) % 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstrhash(bear) = 410     % 10 =  0\nstrhash(fox) = 333     % 10 =  3\n```\n:::\n:::\n\n\nSo we would store our items in cells 0 and 3.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# we can use the numeric indices from our hash to read and write from storage\nstorage[strhash(\"bear\") % capacity] = \"cub\"\nstorage[strhash(\"fox\") % capacity] = \"kit\"\n\nfor word in (\"bear\", \"fox\"):\n    print(f\"A baby {word} is called a {storage[strhash(word) % capacity]}.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nA baby bear is called a cub.\nA baby fox is called a kit.\n```\n:::\n:::\n\n\n### Collisions\n\nIf two pieces of data hash to the same value (modulo capacity), we have a **collision**.\nAttempting to store the key 'kangaroo' would generate such a collision:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nprint(\"strhash('kangaroo') % 10 = \", strhash(\"kangaroo\") % capacity)\nstorage[strhash(\"kangaroo\") % capacity] = \"joey\"\n\nprint(\"\\n\" + str(storage))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstrhash('kangaroo') % 10 =  0\n\n['joey', None, None, 'kit', None, None, None, None, None, None]\n```\n:::\n:::\n\n\nWe've overwritten \"cub\" with \"joey\"!\n\nWhile a better hash function might have spread these values out more in the table, no matter what we'll eventually see collisions.\n\nThe second thing we'll need in addition to our hash function is **collision resolution**.\n\n### Collision Resolution\n\nLike hash functions, we have choices available to us.\n\nThe two most common solutions are **separate chaining** and **open addressing**.\n\n**Separate Chaining**\n\nIn this approach each hash cell itself contains a linked list.\n(Our underlying structure is then an array of lists.)\n\nWhenever two keys collide, we will just append the new (key, value) pair to the end of the list.\n\nTODO: draw picture\n\nThe other family of approaches is *open addressing*.\n\nThis approach includes many algorithms that resolve the collision by picking a new location within the still-flat array, but we will focus on **linear probing**.\n\nWhen attempting to write to a key that collided, we will look and see if the next cell is open, and if not that, the next, and so on.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# NOTE: this implementation is intentionally incomplete!\n\ndef set_with_linear_probe(ht_storage, key, value):\n    \"\"\" add a key to our hash table using linear probing algorithm \"\"\"\n    capacity = len(ht_storage)\n    index = strhash(key) % capacity\n   \n    # search until a space is found\n    while True:\n       if ht_storage[index] is None:\n          # a space has been found, add and exit the loop\n          ht_storage[index] = value\n          break\n       else:\n          # move forward looking for space\n          index += 1\n```\n:::\n\n\nNow, when we see a collision, we walk forward a step.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nstorage = [None] * 10\nset_with_linear_probe(storage, \"bear\", \"cub\")\nset_with_linear_probe(storage, \"fox\", \"kit\")\nset_with_linear_probe(storage, \"kangaroo\", \"joey\")\nprint(storage)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['cub', 'joey', None, 'kit', None, None, None, None, None, None]\n```\n:::\n:::\n\n\n'joey' is now stored in the second index, since index 0 was full.\n\nTODO: show storing keys as well\n\n**When does this still fail?**\n\n---\n\n1. If the `hash` value is near the end of the list, it may reach the end before finding a space.\nIn this case, we wrap around, if there is no room to move forward in the list we loop back to index zero, similarly to how our `% capacity` operation works.\n\n2. Eventually however, there will not be any room left in the hashtable. \n\n### Resizing & Rehashing\n\nLike Python's `list`, we will maintain some empty cells, additional *capacity* beyond what is being stored.\n\nIt is tempting to just grow the capacity:\n\n`ht_storage += [None] * 10`\n\n**But what happens if we do this?**\n\nAll of our access rules are based upon `hash % capacity`!\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nprint(\"strhash('bear') % 10 = \", strhash(\"bear\") % 10)\nprint(\"strhash('bear') % 20 = \", strhash(\"bear\") % 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstrhash('bear') % 10 =  0\nstrhash('bear') % 20 =  10\n```\n:::\n:::\n\n\nWith positions 11-19 now available, the correct location for items will have changed.\n\nSince we use the hash to look items up as well as set them, this means that items would go missing if capacity changed!\n\nInstead, we have to **rehash**.\n\nThis means we need to go through all items & compute new hashes whenever we resize.\n\n**When to rehash?**\n\nIn practice, we will want to keep our usage close to 50% of our capacity.\n\nIf you were to wait until the number of items was very close to capacity, the linear probing would be on average $O(N)$.\n\nConsider the case where our capacity is 10 and we have 9 items already.\n\nIt would seek forward, but all but one cell would be occupied, so it would be searching through $O(N)$ spots.\n(In truth closer to N/2, but still $O(N)$ growth.)\n\nWith 50% capacity, and a **good hash function** that evenly spreads items through our table, it would typically only step forward 0 or 1 space, keeping average runtime close to $O(1)$.\n\n### Hash Table Performance\n\nThe performance of our hash table is determined by the algorithms we choose for our hash function and collision resolution.\n\nWe are aiming for average performance of $O(1)$, but there will be cases that become $O(N)$ as we've seen.\n\n| Operation | Average | Worst Case | \n| --------- | ---- | ---------- |\n| lookup    | O(1) | O(n) |\n| insert    | O(1) | O(n) |\n| delete    | O(1) | O(n) |\n\nA key property for hash tables is that we **do not need to linearly search through them for our data**.\n\nIf you find yourself scanning every element in a hash table, you're doing something wrong.\n\n### Polynomial Hash Function\n\nA good hash function will evenly distribute values across the collection.\n\nThis can be visualized by imagining the worst possible hash function:\n\n```python\ndef badhash(key):\n    return 7000  # every key hashes to same value\n```\n\nThis maximizes our collisions.\nWhile we can resolve this with linear probing, we wind up with a situation where each item is just stored in the next available spot, \nand we're back to $O(N)$ run time.\n\nThe `strhash` we defined above isn't much better in practice: strings tend to be short and use common letters.\n\n`strhash(\"cat\")` == `strhash(\"act\")`\n\nand \n\n`strhash(\"car\")` is just two away from to `strhash(\"cat\")`\n\nPerformance will improve if our hash function distributes the values more evenly.\n\nA common pattern is to use a polynomial hash function.\n\n$$h(x_0, ..., x_n) = (\\sum_{i=0}^{k-1}{c_ip^i})\\mod{m}$$\n\nWhere:\n- $x_0...x_i $ is the sequence\n- $k = len(x)$\n- $c_i$ is the numeric value of the character $x_i$ ($ord(x$ in Python)\n- $p$ is an arbitrary constant.\n- and $m$ is the size of the collection.\n\nAn effective approach is to use Hornerâ€™s method to compute\na polynomial whose coefficients are the integer values of the\ncharacters in a string:\n\n$$\np(x) = a_0 + a_1x + a_2x^2 + a_3x^3 + ... + a_nx^n\n$$\n\nwhich, via Horner's rule is the same as:\n\n$$\n= a_0 + x ( a_1 + x ( a_2 + x( a_3 + ... + x ( a_{n-1} + xa_n) ... )))\n$$\n\nWhere $a_i$ is the integer value for the character at position $i$ in the string and $x$ is a prime constant integer.\n\nIn Python:\n\n```python\nmultiplier = 37 # prime\nhash_value = 0\nhash_value = (hash_value * multiplier + ord(\"a\"))\nhash_value = (hash_value * multiplier + ord(\"b\"))\nhash_value = (hash_value * multiplier + ord(\"c\"))\nhash_value = hash_value % self._capacity\n```\n\n## Further Exploration\n\n* [Hash Table Visualization](https://visualgo.net/en/hashtable?slide=1)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": []
  }
}