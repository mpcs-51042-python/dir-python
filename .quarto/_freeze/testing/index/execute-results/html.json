{
  "hash": "406babc77841a2312c121523fab25f32",
  "result": {
    "engine": "jupyter",
    "markdown": "# Testing {#sec-testing}\n\n---\n\n**Goals**\n\n- Learn to write testable code and useful unit tests.\n- Explore some helpful features of `pytest`.\n\n---\n\nAs you've discovered through working on assignments, tests are useful for ensuring that code works as expected.\n\nYou've been using `pytest` to run tests that have been provided for you, approximating something known as **test-driven development**.\n\nTest-driven development (TDD) is a software development process that involves writing tests before writing the code that will be tested.\nBy recognizing the need for a function & reasoning about what the expected output is, you can write tests that will fail if the code is not working correctly.\n\nThis process helps you think through problems, and you will often find that reaching a solution is much easier if you write tests first.\n\nAs you venture into writing larger programs, whether you adopt a TDD approach or write your tests as you go, you'll find it valuable to write your own tests.\n\n## Writing Testable Code\n\nWe break our code into functions and classes to encapsulate functionality that we intend to reuse.\nThese boundaries also provide a natural place to test our code.\n\nIf you only have one big function that does everything, it can be difficult to test:\n\n```python\n\ndef advance_all_students_with_passing_grades():\n    conn = sqlite3.connect('students.db')\n    c = conn.cursor()\n    c.execute('''\n    SELECT student.id, avg(class.grade) as average \n    FROM students JOIN classes ON students.id = classes.student_id\n    GROUP BY student.id HAVING average >= 70\n    ''')\n    students = c.fetchall()\n    for student in students:\n        c.execute('UPDATE student_enrollment SET grade = grade + 1 WHERE student_id = ?', (student[0],))\n    conn.commit()\n    conn.close()\n\n```\n\nHow would you test this function?  You'd need to have a database with a specific set of data in it and then run the function and check that the data was updated as expected.\n\nIf you break the function up into smaller functions, you can test each function in isolation:\n\n```python\n\ndef get_students(conn, grade_threshold=70):\n    ...\n\ndef advance_student(conn, student):\n    ...\n\n```\n\nNow you can test each function in isolation.\n\nBy having the function take parameters, you can also test the function with different inputs.\n\nIt is also possible to test the function with a mock database connection that doesn't actually connect to a database but provides the same interface.\n\nThis is called \"mocking\" and is a useful technique for testing code that interacts with external systems.\n\n## Writing Tests\n\nThere are many types of tests, but we'll primarily focus on tests that verify a single behavior.\n\nSo if a function should sum a list of positive integers, we might write three distinct tests:\n\n- test that a list of positive integers is correctly summed\n- test that negative numbers raise an error (or whatever the intended behavior is)\n- test that an empty list sums to zero\n\nEach of these could be considered a \"unit\" of the overall behavior.\nThis kind of testing is known as **unit testing**.\n\n### pytest\n\n`pytest` is a third-party library that makes writing tests in Python easier & less verbose than the built-in `unittest` module.\n\nWhen you run `pytest` it will look for files named `test_*.py` in the current directory and its sub-directories. It will then run any functions in those files that start with `test_`.\n\n### assert statements\n\nIn Python, the `assert` statement is used to ensure that a condition is true.\n\nIf the condition is `True`, nothing happens.\nIf the condition is `False`, an `AssertionError` is raised.\n\nYou can also provide a message to be printed if the assertion fails:\n\n```python\nassert 1 == 2, \"1 is not equal to 2\"\n```\n\n::: {.callout-important}\n### assert is not a function! \n\nA common mistake is to treat `assert` like a function, and use parentheses.\n\nThis leads to tests passing unexpectedly when they should fail:\n\n```python\nassert(1 == 2, \"1 is not equal to 2\")\n\n# is equivalent to:\nassert (1 == 2, \"1 is not equal to 2\")\n\n# which becomes:\nassert (False, \"1 is not equal to 2\")\n```\n\nAnd a tuple with two elements is always `True`!\n\n:::\n\n\n### Truthiness\n\nIn Python, every type has an implicit conversion to a boolean value.  This is called \"truthiness\".\n\nThe following values are considered \"falsey\":\n\n* `False`\n* `None`\n* `0`   # int\n* `0.0` # float\n* `0j`  # complex\n* `\"\"`    # empty string\n* `[]`    # empty list\n* `()`   # empty tuple\n* `{}`    # empty dict\n* `set()` # empty set\n\nAll other values are considered `True`.\n\n**Truthiness Demo**:\n\n::: {#059df992 .cell execution_count=1}\n``` {.python .cell-code}\nvalues = [False, None, 0, 0.0, 0j, \"\", [], (), {}, set()]\nvalues += [True, 42, 3.14, \"hello\", [1, 2, 3], {\"a\": 1}]\nfor value in values:\n    # notice we're using the value as a boolean expression here\n    if value:\n        print(f\"{value} is True\")\n    else:\n        print(f\"{value} is False\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFalse is False\nNone is False\n0 is False\n0.0 is False\n0j is False\n is False\n[] is False\n() is False\n{} is False\nset() is False\nTrue is True\n42 is True\n3.14 is True\nhello is True\n[1, 2, 3] is True\n{'a': 1} is True\n```\n:::\n:::\n\n\n## Writing good tests\n\nNext, let's take a look at some simple code and some appropriate unit tests:\n```python\n# my_module.py\nfrom collections import namedtuple\n\nPoint = namedtuple('Point', ['x', 'y'])\n\ndef circle_contains(radius: float, center: Point, point: Point):\n    return (point.x - center.x) ** 2 + (point.y - center.y) ** 2 <= radius ** 2\n\ndef points_within(radius: float, center: Point, points: list[Point]):\n    \"\"\" Find all points within a circle. \"\"\"\n    return [point for point in points if circle_contains(radius, center, point)]\n```\n\n```python\n# test_my_module.py\n\nfrom my_module import circle_contains, points_within\n\norigin = Point(0, 0)\n\ndef test_circle_contains():\n    # centered at origin, radius 1\n    assert circle_contains(1, origin, origin)\n    assert circle_contains(1, origin, Point(.5, .5))\n\ndef test_circle_contains_edge():\n    assert circle_contains(1, origin, Point(1, 0))  # on the circle\n\ndef test_circle_contains_outside():\n    assert not circle_contains(1, origin, Point(1.1, 0))\n```\n\n### One test per \"behavior\"\n\nYou may wonder, why did we write three tests instead of one?\n\n```python\ndef test_circle_contains():\n    # centered at origin, radius 1\n    assert circle_contains(1, origin, origin)\n    assert circle_contains(1, origin, Point(.5, .5))\n    assert circle_contains(1, origin, Point(1, 0))  # on the circle\n    assert not circle_contains(1, origin, Point(1.1, 0))\n```\n\nIf the first assertion fails, the second assertion will not be run.\n\nThis makes it harder to debug the problem:\n\nIf a test named `test_circle_contains_edge` fails that only tests one thing, you have an idea of where to look.\n\nGranular tests make debugging easier.\nConsider assignments you've worked on, and whether or not you'd have appreciated a single test that tested a dozen different expected behaviors.\n\n### Test Readability\n\nTests should be easy to understand.  This means that the test should be written in a way that makes it clear what is being tested and what the expected result is.\n\nMake liberal use of comments and descriptive test names to make it clear what is being tested so that when a modification to the code in the future breaks a test, it is easy to understand why.\n\n### Test Independence\n\nTests should be independent of each other.  This means that if one test fails, it should not affect the outcome of any other test.\n\nThis can be a challenge when testing functions that modify data or global state.\n\nFor example:\n\n```python\ndef test_create_user():\n    db = Database(\"test.db\")\n    db.create_user(username=\"alice\")\n    assert db.get_user(username=\"alice\").id == 1\n\ndef test_delete_user():\n    db = Database(\"test.db\")\n    db.delete_user(username=\"alice\")\n    assert db.get_user(username=\"alice\") is None\n```\n\nThese tests are not independent.  If the first test fails, the second test will fail because the database will be empty.\n\nYou'd instead likely need to do something like this:\n\n```python\ndef create_test_database():\n    remove_file_if_exists(\"test.db\")\n    db = Database(\"test.db\")\n    db.init_schema()\n    return db\n\ndef test_create_user():\n    db = create_test_database()\n    db.create_user(username=\"alice\")\n    assert db.get_user(username=\"alice\").id == 1\n\ndef test_delete_user():\n    db = create_test_database()\n    db.create_user(username=\"alice\")\n    db.delete_user(username=\"alice\")\n    assert db.get_user(username=\"alice\") is None\n```\n\nYou may note that `test_delete_user` will fail if `create_user` doesn't work.\nThere's still a dependency in terms of behavior in this case, but you can see that the tests can now be run independently of one another since each starts with a blank database.\n\n### Test Repeatability\n\nTests should be repeatable.  This means that if a test fails, it should be possible to run it again and get the same result.\n\nThis means that tests should not depend on external factors such as:\n\n* The current time or date\n* Random numbers\n* The state of the network\n* The state of the database\n\nTo reduce the chance of a test failing due to an external factor, you can use a library like `freezegun` to freeze the current time that a test sees.  The `mock` module can be used to mock out external functions so they return consistent data for the purpose of the test.\n\n\n## What tests to write?\n\nWhen considering what to test, usually there are a 1-2 clear behaviors that need to be verified.\n\nFor a string comparison function, you would need to test that `strmatch(\"abc\", \"abc\")` and `strmatch(\"abc\", \"xyz\")` return the expected values.\n\nIt is then worth considering edge cases: what about empty strings? Does the function need to handle non-string input? \n\nA helpful checklist to run through is: **Zero, One, Many, Errors**\n\nIf a function takes a collection of some kind, ensure that it performs as expected with an empty collection, a collection with one element, a collection with many elements, and an expected error condition, such as a dictionary passed instead of a list.\n\nYou **do not** need to test multiple iterations of the same behavior.\nIf `sum` works with 4 elements, it probably works with 3 and 5 as well.\n\n```python\n# example tests for the sum() function\ndef test_sum_empty():\n    assert sum([]) == 0\n\ndef test_sum_one():\n    assert sum([1]) == 1\n\ndef test_sum_many():\n    assert sum([1, 2, 3]) == 6\n\ndef test_sum_type_error():\n    with pytest.raises(TypeError):\n        sum([1, \"hello\"])\n```\n\n## `pytest` Features\n\nWe use `pytest` because it is easy to use and provides a lot of useful features, especially when contrasted with Python's built-in `unittest`.\n\n`pytest` provides both a command line tool `pytest`, which you've been using, and a library that you can use to help you write tests.\n\n### CLI Flags\n\n`pytest` has some helpful command line options, among them:\n\n- Passing a filename like `tests/test_markov.py` will run only the tests in that file.\n- `-v` will print out more information about each test and give more detailed error output.\n- `-vv` will print out even more information about each test, particularly useful when comparing expected output vs. actual.\n- `-s` will include any output from `print` statements (normally suppressed by `pytest`).\n- `-k <pattern>` will only run tests whose names match the pattern. (So `pytest -k frontend` would match `test_frontend_template` and `test_frontend_call` but not `test_database_setup`)\n- `-x` will stop running tests after the first failure.\n\n### Fixtures\n\nA fixture is a function that is run before each test.\nIt can be used to set up the test environment or provide consistent test data.\n\n```python\nimport pytest\n\n@pytest.fixture\ndef user_list()\n    return [\n        {\"name\": \"alice\", \"id\": 1, \"email\": \"alice@domain\"},\n        {\"name\": \"carol\", \"id\": 3, \"email\": \"carol@domain\"},\n        {\"name\": \"bob\", \"id\": 2, \"email\": \"bob@domain\"},\n        {\"name\": \"diego\", \"id\": 4, \"email\": \"diego@otherdomain\"},\n    ]\n\ndef test_sort_users(user_list):\n    sorted_list = sort_users(user_list)\n    assert sorted_list == [\n        {\"name\": \"alice\", \"id\": 1, \"email\": \"alice@domain\"},\n        {\"name\": \"bob\", \"id\": 2, \"email\": \"bob@domain\"},\n        {\"name\": \"carol\", \"id\": 3, \"email\": \"carol@domain\"},\n        {\"name\": \"diego\", \"id\": 4, \"email\": \"diego@otherdomain\"},\n    ]\n\ndef test_filter_users(user_list):\n    filtered_list = filter_users(user_list, domain=\"domain\")\n    assert filtered_list == [\n        {\"name\": \"alice\", \"id\": 1, \"email\": \"alice@domain\"},\n        {\"name\": \"bob\", \"id\": 2, \"email\": \"bob@domain\"},\n        {\"name\": \"carol\", \"id\": 3, \"email\": \"carol@domain\"},\n    ]\n```\n\nThis is a powerful feature that can be used to set up complex test environments and ensure **test independence** as described above.\n```python\nimport pytest\n\n@pytest.fixture\ndef db():\n    remove_file_if_exists(\"test.db\")\n    db = Database(\"test.db\")\n    db.init_schema()\n    return db\n\n# parameter names must match fixture names\ndef test_create_user(db):\n    db.create_user(username=\"alice\")\n    assert db.get_user(username=\"alice\").id == 1\n\ndef test_delete_user(db):\n    db.create_user(username=\"alice\")\n    db.delete_user(username=\"alice\")\n    assert db.get_user(username=\"alice\") is None\n```\n\n### Testing Exceptions\n\nEnsuring that your functions handle errors as intended is an important behavior to include in your tests.\n\n`pytest.raises` can be used to ensure that a function raises an exception.\n\n```python\ndef test_reject_invalid_domain():\n    with pytest.raises(ValueError):\n        validate_email(\"alice@invalid$\")\n```\n\nIf the exception **is not** raised within the `with` block, `pytest` will mark the test as failed.\n\n### Parameterized Tests\n\nSometimes the same test needs to be run with different inputs. `pytest` provides a way to do this with parameterized tests.\n\n```python\n@pytest.mark.parametrize(\"str1,str2,expected\", [\n    (\"abc\", \"abd\", 1),\n    (\"abc\", \"abc\", 0),\n    (\"abc\", \"xyz\", 3),\n])\ndef test_hamming_distance(str1, str2, expected):\n    assert hamming_distance(str1, str2) == expected\n```\n\nThis runs as three distinct tests in `pytest`, converting each input to a distinct test by calling the test function with the parameters.\n\n\n## Beyond Unit Testing\n\nWhile unit testing is the most common type of testing, it can be important to test that the various components work together as expected as well.\nThis is known as **integration testing**.\n\nYou will also encounter **functional testing** and **end-to-end testing** which are similar concepts, ensuring that the system works as intended, not just the individual parts.\n\nThese tests are typically much more complex and take a longer amount of time to run.\nIn practice, you may run the unit tests every time you make a commit, but only run larger tests before a release.\n\n**Performance testing** focuses on the speed at which a piece of code runs, often set up to watch for regressions where a change makes the code notably slower.\n\n## Further Exploration\n\n- [pytest](https://docs.pytest.org/en/stable/)\n- [freezegun](https://github.com/spulec/freezegun)\n- [mock](https://docs.python.org/3/library/unittest.mock.html)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}